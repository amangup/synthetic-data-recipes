{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782e106a-547e-46a9-97ed-40d9e6f37511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.cluster import KMeans\n",
    "from vllm import LLM\n",
    "\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e8b141-5ff4-4efb-afe0-d6e05bbc1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "personas_ds = load_dataset('amang1802/personas_sample_405B')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a160ebc1-e46a-4271-863e-32a3261bf942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Alibaba-NLP/gte-Qwen2-7B-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd1a537-564c-4957-abe7-21e39daafc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Identify the name, profession and personality of the person described.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32b7693-63a0-48c2-85b5-7eaa55cd49da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-24 08:46:00 config.py:274] Overriding HF config with {'is_causal': False}\n",
      "INFO 12-24 08:46:00 config.py:2167] Downcasting torch.float32 to torch.float16.\n",
      "INFO 12-24 08:46:05 config.py:478] This model supports multiple tasks: {'generate', 'score', 'reward', 'embed', 'classify'}. Defaulting to 'embed'.\n",
      "INFO 12-24 08:46:05 llm_engine.py:249] Initializing an LLM engine (v0.6.5) with config: model='Alibaba-NLP/gte-Qwen2-7B-instruct', speculative_config=None, tokenizer='Alibaba-NLP/gte-Qwen2-7B-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Alibaba-NLP/gte-Qwen2-7B-instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, mm_cache_preprocessor=False, mm_processor_kwargs=None, pooler_config=PoolerConfig(pooling_type='LAST', normalize=True, softmax=None, step_tag_id=None, returned_token_ids=None), compilation_config={\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"candidate_compile_sizes\":[],\"compile_sizes\":[],\"capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Alibaba-NLP/gte-Qwen2-7B-instruct:\n",
      "- tokenization_qwen.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-24 08:46:07 selector.py:120] Using Flash Attention backend.\n",
      "INFO 12-24 08:46:08 model_runner.py:1092] Starting to load model Alibaba-NLP/gte-Qwen2-7B-instruct...\n",
      "INFO 12-24 08:46:09 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4a19564eaa444dbcc6c181cbc71ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/7 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-24 08:46:18 model_runner.py:1097] Loading model weights took 13.2529 GB\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(model=model_id, trust_remote_code=True, max_model_len=4096, hf_overrides={\"is_causal\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2082f669-d348-48e1-895f-e435fde2e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(personas):\n",
    "    instruct_chunks = [\"Instruct: \" + instruction + \"\\nQuery:\\n\" + json.dumps(pjson, indent=2) for pjson in personas]\n",
    "    outputs = llm.embed(instruct_chunks)\n",
    "\n",
    "    return {\"embedding\": [output.outputs.embedding for output in outputs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc2512c-71be-4042-a074-c78f72aff765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function compute_embedding at 0x7a69d5032830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08f3a7a38d74d83b4f9efcdcc22d8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Acessed prompts:   0% 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:   0% 1/1024 [00:01<20:25,  1.20s/it, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:   9% 96/1024 [00:01<00:10, 92.39it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  12% 127/1024 [00:02<00:13, 64.37it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  16% 159/1024 [00:03<00:16, 53.11it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  19% 190/1024 [00:03<00:17, 48.59it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  22% 221/1024 [00:04<00:17, 45.91it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  25% 253/1024 [00:05<00:17, 44.08it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  28% 285/1024 [00:06<00:17, 42.97it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  31% 317/1024 [00:06<00:16, 42.27it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  34% 349/1024 [00:07<00:15, 42.30it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  37% 381/1024 [00:08<00:15, 40.77it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  40% 412/1024 [00:09<00:15, 40.52it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  43% 443/1024 [00:10<00:14, 40.46it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  46% 475/1024 [00:10<00:13, 41.27it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  49% 506/1024 [00:11<00:12, 41.07it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  52% 537/1024 [00:12<00:11, 40.66it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  56% 569/1024 [00:13<00:11, 40.90it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  59% 600/1024 [00:13<00:10, 40.77it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  62% 631/1024 [00:14<00:09, 39.73it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  65% 663/1024 [00:15<00:09, 39.48it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  68% 694/1024 [00:16<00:08, 39.73it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  71% 726/1024 [00:17<00:07, 40.89it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  74% 757/1024 [00:17<00:06, 41.43it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  77% 788/1024 [00:18<00:05, 41.15it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  80% 820/1024 [00:19<00:04, 41.24it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  83% 852/1024 [00:20<00:04, 41.28it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  86% 884/1024 [00:20<00:03, 41.15it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  89% 916/1024 [00:21<00:02, 40.93it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  93% 948/1024 [00:22<00:01, 41.01it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  96% 978/1024 [00:23<00:01, 40.22it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts: 100% 1024/1024 [00:23<00:00, 42.69it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\n",
      "\u001b[Acessed prompts:   0% 0/978 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:   7% 64/978 [00:00<00:02, 333.13it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  10% 98/978 [00:00<00:10, 86.53it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s] \n",
      "\u001b[Acessed prompts:  13% 127/978 [00:01<00:14, 59.81it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  16% 159/978 [00:02<00:15, 51.35it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  19% 190/978 [00:03<00:16, 46.74it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  23% 221/978 [00:04<00:17, 44.02it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  26% 252/978 [00:04<00:17, 42.38it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  29% 284/978 [00:05<00:16, 42.04it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  32% 315/978 [00:06<00:15, 41.48it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  35% 346/978 [00:07<00:15, 41.16it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  39% 378/978 [00:07<00:14, 41.15it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  42% 409/978 [00:08<00:13, 40.86it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  45% 440/978 [00:09<00:13, 40.79it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  48% 472/978 [00:10<00:12, 41.06it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  52% 504/978 [00:11<00:11, 40.97it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  55% 535/978 [00:11<00:10, 40.43it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  58% 567/978 [00:12<00:10, 40.66it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  61% 598/978 [00:13<00:09, 40.24it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  64% 630/978 [00:14<00:08, 40.23it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  68% 661/978 [00:15<00:07, 40.04it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  71% 692/978 [00:15<00:07, 39.69it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  74% 723/978 [00:16<00:06, 39.75it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  77% 754/978 [00:17<00:05, 39.93it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  80% 786/978 [00:18<00:04, 40.37it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  84% 817/978 [00:18<00:03, 40.43it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  87% 848/978 [00:19<00:03, 40.38it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  90% 879/978 [00:20<00:02, 40.37it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  93% 911/978 [00:21<00:01, 39.70it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "\u001b[Acessed prompts:  96% 943/978 [00:22<00:00, 40.15it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
      "Processed prompts: 100% 978/978 [00:22<00:00, 42.88it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n"
     ]
    }
   ],
   "source": [
    "embed_ds = personas_ds.map(compute_embedding, input_columns=['persona'], batched=True, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd862323-1b31-4c85-85f7-cd60a8676ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.array(embed_ds['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35757a4-bc3d-40bf-98d7-22247eb993f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93727d30-8821-41de-87cc-8cb3a9142d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "clusters = kmeans.fit_predict(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e70f27c7-569e-4ad2-84c8-a2694d8f3a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_clusters = np.unique(clusters)\n",
    "uniq_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70babaeb-09b8-4a5c-b006-0b9883fc0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_ids = []\n",
    "for idk in uniq_clusters:\n",
    "    cluster_points = embeds[clusters == idk, :]\n",
    "    centroid = cluster_points.mean(axis=0)\n",
    "    cluster_centroid_dist = np.linalg.norm(embeds - centroid, axis=1)\n",
    "    nearest_index = np.argmin(cluster_centroid_dist)\n",
    "    centroid_ids.append(nearest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8f1d2a-46ff-4164-ab3b-fa87af35df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(centroid_ids) == len(uniq_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1656b4a-c600-4c87-ae81-258c0e87ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cluster_centroid(idx):\n",
    "    return {\"is_cluster_centroid\": idx in centroid_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ed72d09-6edb-472a-bfc6-e4afe2d9bde9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dac055b6b54779b8b8156fa6cd0fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "centroid_ds = embed_ds.map(lambda _, idx: is_cluster_centroid(idx), with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8547f3-5252-4743-a936-92fc3207f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aba7f5ae50d4086b6c8a97d47d4f728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2446f05f608461081e1d772c9648f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1f7848ef994be09a6a67614a4f89da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/lfs.py:337: UserWarning: hf_transfer is enabled but does not support uploading from bytes or BinaryIO, falling back to regular upload\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/amang1802/personas_sample_405B/commit/c8d43a76a3a2de864372acbb1ff21f61609b2ce4', commit_message='Upload dataset', commit_description='', oid='c8d43a76a3a2de864372acbb1ff21f61609b2ce4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/amang1802/personas_sample_405B', endpoint='https://huggingface.co', repo_type='dataset', repo_id='amang1802/personas_sample_405B'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_ds.push_to_hub('amang1802/personas_sample_405B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbb35d-5f0f-48a9-a480-751d60c6e7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
