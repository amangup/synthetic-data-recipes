{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42468fe9-bbf9-4578-946b-28a40af5606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4ba340-f20f-4c06-a416-335eea5ebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94d37b8-38ad-497d-85ba-ebe288f8d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '/root/synthetic-data-recipes/diversity/ft_models/llama3_1_8B/fulltext_conditioned_10epochs_lr1e-5/epoch_9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82df75f-3134-4eb6-9c19-f03e3bf6ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9add8172-17d6-4ee0-adbf-55906ee736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 16\n",
    "batch_size = 4\n",
    "num_samples = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d894c338-7268-4358-a094-b930d5d64376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65f67167d2949399011d6801c6f73b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(\"cuda:0\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af82545e-7ba6-4a32-871f-1b1408561f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_batch(batch):\n",
    "    encodings = tokenizer(\n",
    "            batch,\n",
    "            padding='longest',\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda:0\")\n",
    "    \n",
    "    return encodings\n",
    "\n",
    "def get_shift_labels(encodings):\n",
    "    labels = encodings.input_ids.clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    labels[:, :context_length] = -100\n",
    "    shift_labels = labels[:, 1:]\n",
    "\n",
    "    return shift_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b9419a-fbfc-4e87-a913-91ec3668860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compute_perplexity(texts, context_length, batch_size):\n",
    "    nll_sum = torch.tensor(0, dtype=torch.float64, requires_grad=False).to(\"cuda:0\")\n",
    "    n_tokens = torch.tensor(0, dtype=torch.int64, requires_grad=False).to(\"cuda:0\")\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        #print(f\"processing batch: {i//batch_size} out of {len(texts)//batch_size}\")\n",
    "\n",
    "        batch = texts[i:i + batch_size]\n",
    "        encodings = get_tokens_batch(batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            shift_logits = model(\n",
    "                input_ids=encodings.input_ids,\n",
    "                attention_mask=encodings.attention_mask\n",
    "            ).logits[:, :-1]\n",
    "        \n",
    "        shift_labels = get_shift_labels(encodings)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            shift_logits.reshape(-1, shift_logits.size(-1)),\n",
    "            shift_labels.reshape(-1),\n",
    "            ignore_index=-100\n",
    "        ).type(torch.float64)\n",
    "        \n",
    "        #print(loss)\n",
    "\n",
    "        num_valid_tokens = (shift_labels != -100).sum()\n",
    "        \n",
    "        nll_sum += loss * num_valid_tokens\n",
    "        n_tokens += num_valid_tokens\n",
    "            \n",
    "    avg_nll = nll_sum / n_tokens\n",
    "    ppl = torch.exp(avg_nll)\n",
    "        \n",
    "    return nll_sum, n_tokens, avg_nll, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43cdd3b-dda2-4e1f-bf63-25b4dcf2fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [\n",
    "    # 'amang1802/synthetic_data_topic_conditioned_L3.3_70B_deduped',\n",
    "    # 'amang1802/synthetic_data_prefix_conditioned_L3.3_70B_deduped',\n",
    "    'amang1802/synthetic_data_fulltext_conditioned_L3.3_70B_deduped'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256fd1f-1547-4f15-8a45-fc9a2d24b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amang1802/synthetic_data_fulltext_conditioned_L3.3_70B_deduped train (tensor(340549.3350, device='cuda:0', dtype=torch.float64), tensor(545041, device='cuda:0'), tensor(0.6248, device='cuda:0', dtype=torch.float64), tensor(1.8679, device='cuda:0', dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "for ds_id in ds_list:\n",
    "    ds = load_dataset(ds_id)\n",
    "    for split in ['train', 'test']:    \n",
    "        texts = ds[split].shuffle(seed=1998).select(range(num_samples))['synthetic_content']\n",
    "        metrics = batch_compute_perplexity(texts, context_length, batch_size)\n",
    "        print(ds_id, split, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99478e2-1821-4ca7-933b-00153e02163c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
