{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42468fe9-bbf9-4578-946b-28a40af5606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4ba340-f20f-4c06-a416-335eea5ebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f94d37b8-38ad-497d-85ba-ebe288f8d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-3.1-8B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82df75f-3134-4eb6-9c19-f03e3bf6ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9add8172-17d6-4ee0-adbf-55906ee736ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 16\n",
    "batch_size = 4\n",
    "num_samples = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d894c338-7268-4358-a094-b930d5d64376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef6b12dbbda41fcad26d2c64ffb3fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(\"cuda:0\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af82545e-7ba6-4a32-871f-1b1408561f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_batch(batch):\n",
    "    encodings = tokenizer(\n",
    "            batch,\n",
    "            padding='longest',\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda:0\")\n",
    "    \n",
    "    return encodings\n",
    "\n",
    "def get_shift_labels(encodings):\n",
    "    labels = encodings.input_ids.clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    labels[:, :context_length] = -100\n",
    "    shift_labels = labels[:, 1:]\n",
    "\n",
    "    return shift_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b9419a-fbfc-4e87-a913-91ec3668860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compute_perplexity(texts, context_length, batch_size):\n",
    "    nll_sum = torch.tensor(0, dtype=torch.float64, requires_grad=False).to(\"cuda:0\")\n",
    "    n_tokens = torch.tensor(0, dtype=torch.int64, requires_grad=False).to(\"cuda:0\")\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        print(f\"processing batch: {i//batch_size} out of {len(texts)//batch_size}\")\n",
    "\n",
    "        batch = texts[i:i + batch_size]\n",
    "        encodings = get_tokens_batch(batch)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            shift_logits = model(\n",
    "                input_ids=encodings.input_ids,\n",
    "                attention_mask=encodings.attention_mask\n",
    "            ).logits[:, :-1]\n",
    "        \n",
    "        shift_labels = get_shift_labels(encodings)\n",
    "        \n",
    "        loss = torch.nn.functional.cross_entropy(\n",
    "            shift_logits.reshape(-1, shift_logits.size(-1)),\n",
    "            shift_labels.reshape(-1),\n",
    "            ignore_index=-100\n",
    "        ).type(torch.float64)\n",
    "        \n",
    "        print(loss)\n",
    "\n",
    "        num_valid_tokens = (shift_labels != -100).sum()\n",
    "        \n",
    "        nll_sum += loss * num_valid_tokens\n",
    "        n_tokens += num_valid_tokens\n",
    "            \n",
    "    avg_nll = nll_sum / n_tokens\n",
    "    ppl = torch.exp(avg_nll)\n",
    "        \n",
    "    return nll_sum, n_tokens, avg_nll, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5dd26d-12e5-42e9-b900-0a09a7710f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('amang1802/synthetic_data_fulltext_conditioned_L3.3_70B')['train'].shuffle(seed=1998).select(range(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "046f5ed1-0662-4eca-a9eb-b6b8ddf5dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ds['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8657a495-4779-4571-a65b-f7a14fd53e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch: 0 out of 128\n",
      "tensor(1.6328, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 1 out of 128\n",
      "tensor(2.0938, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 2 out of 128\n",
      "tensor(1.7500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 3 out of 128\n",
      "tensor(1.7031, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 4 out of 128\n",
      "tensor(1.9453, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 5 out of 128\n",
      "tensor(1.7734, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 6 out of 128\n",
      "tensor(1.8594, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 7 out of 128\n",
      "tensor(1.5391, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 8 out of 128\n",
      "tensor(1.7500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 9 out of 128\n",
      "tensor(1.8438, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 10 out of 128\n",
      "tensor(2.2344, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 11 out of 128\n",
      "tensor(1.6562, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 12 out of 128\n",
      "tensor(1.9141, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 13 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 14 out of 128\n",
      "tensor(1.2188, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 15 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 16 out of 128\n",
      "tensor(1.7578, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 17 out of 128\n",
      "tensor(1.7734, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 18 out of 128\n",
      "tensor(1.6797, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 19 out of 128\n",
      "tensor(1.5469, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 20 out of 128\n",
      "tensor(2.0312, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 21 out of 128\n",
      "tensor(2.1250, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 22 out of 128\n",
      "tensor(1.8672, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 23 out of 128\n",
      "tensor(0.7812, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 24 out of 128\n",
      "tensor(1.6719, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 25 out of 128\n",
      "tensor(1.8750, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 26 out of 128\n",
      "tensor(1.3828, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 27 out of 128\n",
      "tensor(1.6875, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 28 out of 128\n",
      "tensor(1.5938, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 29 out of 128\n",
      "tensor(1.8672, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 30 out of 128\n",
      "tensor(1.7578, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 31 out of 128\n",
      "tensor(1.4375, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 32 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 33 out of 128\n",
      "tensor(1.8125, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 34 out of 128\n",
      "tensor(1.5469, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 35 out of 128\n",
      "tensor(1.7109, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 36 out of 128\n",
      "tensor(1.8750, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 37 out of 128\n",
      "tensor(1.7500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 38 out of 128\n",
      "tensor(1.5391, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 39 out of 128\n",
      "tensor(1.4531, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 40 out of 128\n",
      "tensor(1.5391, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 41 out of 128\n",
      "tensor(2.1875, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 42 out of 128\n",
      "tensor(1.8984, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 43 out of 128\n",
      "tensor(1.2500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 44 out of 128\n",
      "tensor(1.6875, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 45 out of 128\n",
      "tensor(1.2578, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 46 out of 128\n",
      "tensor(1.3516, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 47 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 48 out of 128\n",
      "tensor(2.0156, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 49 out of 128\n",
      "tensor(1.5078, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 50 out of 128\n",
      "tensor(1.1016, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 51 out of 128\n",
      "tensor(1.8672, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 52 out of 128\n",
      "tensor(2.2344, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 53 out of 128\n",
      "tensor(1.7578, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 54 out of 128\n",
      "tensor(1.3125, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 55 out of 128\n",
      "tensor(1.6719, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 56 out of 128\n",
      "tensor(1.7344, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 57 out of 128\n",
      "tensor(1.5703, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 58 out of 128\n",
      "tensor(2.0312, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 59 out of 128\n",
      "tensor(2.0469, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 60 out of 128\n",
      "tensor(1.9609, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 61 out of 128\n",
      "tensor(1.5625, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 62 out of 128\n",
      "tensor(1.9766, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 63 out of 128\n",
      "tensor(1.8438, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 64 out of 128\n",
      "tensor(1.8594, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 65 out of 128\n",
      "tensor(1.8594, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 66 out of 128\n",
      "tensor(1.6562, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 67 out of 128\n",
      "tensor(1.4062, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 68 out of 128\n",
      "tensor(1.6797, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 69 out of 128\n",
      "tensor(2., device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 70 out of 128\n",
      "tensor(1.5234, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 71 out of 128\n",
      "tensor(1.4922, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 72 out of 128\n",
      "tensor(1.5391, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 73 out of 128\n",
      "tensor(1.7734, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 74 out of 128\n",
      "tensor(1.7969, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 75 out of 128\n",
      "tensor(1.7109, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 76 out of 128\n",
      "tensor(2.1406, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 77 out of 128\n",
      "tensor(1.4453, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 78 out of 128\n",
      "tensor(1.7891, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 79 out of 128\n",
      "tensor(1.3984, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 80 out of 128\n",
      "tensor(2.1094, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 81 out of 128\n",
      "tensor(1.2266, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 82 out of 128\n",
      "tensor(1.7500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 83 out of 128\n",
      "tensor(1.8125, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 84 out of 128\n",
      "tensor(1.3438, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 85 out of 128\n",
      "tensor(1.7500, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 86 out of 128\n",
      "tensor(1.8438, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 87 out of 128\n",
      "tensor(2.1250, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 88 out of 128\n",
      "tensor(1.5078, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 89 out of 128\n",
      "tensor(1.6719, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 90 out of 128\n",
      "tensor(2.3594, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 91 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 92 out of 128\n",
      "tensor(1.9922, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 93 out of 128\n",
      "tensor(1.5234, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 94 out of 128\n",
      "tensor(1.8047, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 95 out of 128\n",
      "tensor(1.6953, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 96 out of 128\n",
      "tensor(1.7031, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 97 out of 128\n",
      "tensor(2.1094, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 98 out of 128\n",
      "tensor(1.6094, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 99 out of 128\n",
      "tensor(1.4531, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 100 out of 128\n",
      "tensor(1.7734, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 101 out of 128\n",
      "tensor(1.8125, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 102 out of 128\n",
      "tensor(1.6016, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 103 out of 128\n",
      "tensor(1.4609, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 104 out of 128\n",
      "tensor(1.6484, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 105 out of 128\n",
      "tensor(2.0938, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 106 out of 128\n",
      "tensor(1.9844, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 107 out of 128\n",
      "tensor(1.9062, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 108 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 109 out of 128\n",
      "tensor(1.7656, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 110 out of 128\n",
      "tensor(1.6719, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 111 out of 128\n",
      "tensor(1.5469, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 112 out of 128\n",
      "tensor(1.6250, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 113 out of 128\n",
      "tensor(1.5469, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 114 out of 128\n",
      "tensor(1.8281, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 115 out of 128\n",
      "tensor(1.8438, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 116 out of 128\n",
      "tensor(1.3906, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 117 out of 128\n",
      "tensor(0.8633, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 118 out of 128\n",
      "tensor(1.7422, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 119 out of 128\n",
      "tensor(1.6094, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 120 out of 128\n",
      "tensor(1.7031, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 121 out of 128\n",
      "tensor(1.5547, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 122 out of 128\n",
      "tensor(1.1875, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 123 out of 128\n",
      "tensor(0.8477, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 124 out of 128\n",
      "tensor(1.7578, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 125 out of 128\n",
      "tensor(1.8672, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 126 out of 128\n",
      "tensor(1.7188, device='cuda:0', dtype=torch.float64)\n",
      "processing batch: 127 out of 128\n",
      "tensor(1.8750, device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(443614.0547, device='cuda:0', dtype=torch.float64),\n",
       " tensor(258385, device='cuda:0'),\n",
       " tensor(1.7169, device='cuda:0', dtype=torch.float64),\n",
       " tensor(5.5671, device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_compute_perplexity(texts, context_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99478e2-1821-4ca7-933b-00153e02163c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
